# chat-demo

接口：
```
http://localhost:11434
```

目标： 接入本地ollama模型，实现与ollama模型的对话。
聊天存储到indexDB中，可以离线使用。

技术栈：
- react
- react-router-dom
- antd
- axios
后端：
- ollama


待实现：
- 数据三方管理(前端管理)
- 聊天记录存储
- 聊天记录本地持久化
