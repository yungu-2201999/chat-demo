# chat-demo

接口：
```
http://localhost:11434
```

目标： 接入本地ollama模型，实现与ollama模型的对话。
聊天存储到indexDB中，可以离线使用。

技术栈：
- react
- react-router-dom
- antd
- axios
后端：
- ollama
